# -*- coding: utf-8 -*-
"""
ANÁLISE BIBLIOMÉTRICA: ARTIGOS SCIELO COM FOCO EM INTELIGÊNCIA ARTIFICIAL
Versão otimizada com correções e código limpo
Autor: Análise Automatizada
Data: Novembro 2025
"""

import re
import os
import csv
from collections import defaultdict, Counter
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

# Configurações gerais
sns.set_style("whitegrid")
plt.rcParams['font.size'] = 10
plt.rcParams['figure.max_open_warning'] = 50

# ============================================================================
# CONFIGURAÇÃO DOS ARQUIVOS
# ============================================================================

BASE_DIR = r'C:\Users\julia\Downloads'
OUTPUT_DIR = r'C:\Users\julia\Downloads\resultados_analise'

# Arquivos de entrada
ARQUIVO_RIS = os.path.join(BASE_DIR, 'export_scielo.ris')
CSV_AREAS = os.path.join(BASE_DIR, 'scielo_areas_tematicas.csv')
CSV_CITAVEL = os.path.join(BASE_DIR, 'scielo_citavel_naocitavel.csv')
CSV_CITACOES = os.path.join(BASE_DIR, 'scielo_indice_citacoes.csv')
CSV_PERIODICOS = os.path.join(BASE_DIR, 'scielo_periódicos.csv')
CSV_ANO = os.path.join(BASE_DIR, 'scielo_publi_ano.csv')
CSV_LITERATURA = os.path.join(BASE_DIR, 'scielo_tipo__literatura.csv')

os.makedirs(OUTPUT_DIR, exist_ok=True)

# ============================================================================
# FUNÇÕES DE LEITURA DE DADOS
# ============================================================================

def ler_csv_generico(caminho_csv):
    """Lê arquivo CSV e retorna dicionário com os dados"""
    dados = {}
    try:
        with open(caminho_csv, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            for row in reader:
                chave = list(row.values())[0]
                valor = int(list(row.values())[1])
                dados[chave] = valor
        print(f"✓ CSV carregado: {os.path.basename(caminho_csv)} ({len(dados)} registros)")
    except Exception as e:
        print(f"⚠ Erro ao ler {os.path.basename(caminho_csv)}: {e}")
    return dados

def consolidar_areas_tematicas(areas_dict):
    """
    Consolida categorias similares nas áreas temáticas
    (ex: Education + Educational = Education & Educational Research)
    """
    areas_consolidadas = {}
    categorias_processadas = set()
    
    # Mapeamento de categorias similares
    grupos_similares = {
        frozenset(['Education', 'Educational']): 'Education & Educational Research',
        frozenset(['Language', 'Linguística']): 'Language & Linguistics',
    }
    
    # Processar grupos similares
    for grupo, nome_consolidado in grupos_similares.items():
        total = sum(areas_dict.get(cat, 0) for cat in grupo)
        if total > 0:
            areas_consolidadas[nome_consolidado] = total
            categorias_processadas.update(grupo)
    
    # Adicionar categorias não consolidadas
    for categoria, valor in areas_dict.items():
        if categoria not in categorias_processadas:
            areas_consolidadas[categoria] = valor
    
    return areas_consolidadas

def carregar_dados_csv():
    """Carrega todos os arquivos CSV"""
    print("\n" + "="*80)
    print("CARREGAMENTO DOS DADOS CSV")
    print("="*80)
    
    dados_csv = {
        'areas_tematicas': ler_csv_generico(CSV_AREAS),
        'citavel': ler_csv_generico(CSV_CITAVEL),
        'citacoes': ler_csv_generico(CSV_CITACOES),
        'periodicos': ler_csv_generico(CSV_PERIODICOS),
        'ano': ler_csv_generico(CSV_ANO),
        'literatura': ler_csv_generico(CSV_LITERATURA)
    }
    
    # Consolidar áreas temáticas
    print("\n→ Consolidando categorias similares...")
    dados_csv['areas_tematicas'] = consolidar_areas_tematicas(dados_csv['areas_tematicas'])
    print(f"✓ Áreas consolidadas: {len(dados_csv['areas_tematicas'])} categorias únicas")
    
    return dados_csv

# ============================================================================
# FUNÇÕES DE PROCESSAMENTO DO ARQUIVO RIS
# ============================================================================

def ler_arquivo_ris(caminho_ris):
    """Lê arquivo RIS e divide em registros"""
    print("\n" + "="*80)
    print("LEITURA DO ARQUIVO RIS")
    print("="*80)
    print(f"Arquivo: {caminho_ris}")
    
    try:
        with open(caminho_ris, 'r', encoding='utf-8', errors='ignore') as f:
            conteudo = f.read()
        
        records = [r for r in re.split(r'ER\s+-\s*\n', conteudo) if r.strip()]
        print(f"✓ {len(records)} registros encontrados")
        return records
        
    except FileNotFoundError:
        print(f"✗ ERRO: Arquivo não encontrado!")
        return []
    except Exception as e:
        print(f"✗ ERRO: {e}")
        return []

def extrair_dados_artigo(record):
    """Extrai informações de um registro RIS"""
    if not record.strip():
        return None
    
    # Padrões de extração
    patterns = {
        'title': r'TI\s+-\s*(.+?)(?=\n[A-Z]{2}\s+-\s+|$)',
        'abstract': r'AB\s+-\s*(.+?)(?=\n[A-Z]{2}\s+-\s+|$)',
        'keywords': r'KW\s+-\s*(.+)',
        'year': r'PY\s+-\s*(\d{4})',
        'journal': r'JO\s+-\s*(.+)',
        'language': r'LA\s+-\s*(.+)',
        'type': r'TY\s+-\s*(.+)'
    }
    
    # Extrair dados
    title_match = re.search(patterns['title'], record, re.DOTALL)
    if not title_match:
        return None
    
    abstract_matches = re.findall(patterns['abstract'], record, re.DOTALL)
    keywords_matches = re.findall(patterns['keywords'], record)
    year_match = re.search(patterns['year'], record)
    journal_match = re.search(patterns['journal'], record)
    language_match = re.search(patterns['language'], record)
    type_match = re.search(patterns['type'], record)
    
    return {
        'title': title_match.group(1).strip().replace('\n', ' '),
        'abstract': ' '.join([a.strip().replace('\n', ' ') for a in abstract_matches]),
        'keywords': [k.strip() for k in keywords_matches],
        'year': year_match.group(1) if year_match else "N/A",
        'journal': journal_match.group(1).strip() if journal_match else "N/A",
        'language': language_match.group(1).strip() if language_match else "N/A",
        'type': type_match.group(1).strip() if type_match else "N/A"
    }

def verificar_foco_ia(artigo):
    """Determina se o artigo tem IA como foco principal"""
    
    ia_keywords_principais = [
        'inteligência artificial', 'artificial intelligence', 'inteligencia artificial',
        'machine learning', 'aprendizado de máquina', 'deep learning',
        'chatgpt', 'gpt'
    ]
    
    ia_keywords_secundarias = [
        'neural network', 'rede neural', 'algoritmo', 'algorithm', 
        'automação', 'automation', 'ia ', ' ai ', 'dados', 'data'
    ]
    
    # Preparar textos
    title_lower = artigo['title'].lower()
    abstract_lower = artigo['abstract'].lower()
    keywords_lower = ' '.join(artigo['keywords']).lower()
    
    # Verificar menções
    all_keywords = ia_keywords_principais + ia_keywords_secundarias
    mentions_ai = any(kw in title_lower or kw in abstract_lower or kw in keywords_lower 
                     for kw in all_keywords)
    
    # Verificar foco principal
    about_ai = False
    if mentions_ai:
        if any(kw in title_lower for kw in ia_keywords_principais):
            about_ai = True
        elif any(kw.lower() in keywords_lower.split()[:10] for kw in ia_keywords_principais):
            about_ai = True
    
    artigo['mentions_ai'] = mentions_ai
    artigo['about_ai'] = about_ai
    
    return artigo

def categorizar_artigo(artigo):
    """Categoriza artigo por tema principal"""
    
    categorias = {
        'Educação': [
            'educação', 'education', 'ensino', 'teaching', 'aprendizagem', 
            'learning', 'escola', 'professor', 'teacher', 'estudante', 
            'student', 'pedagog', 'didát', 'currículo', 'curriculum'
        ],
        'Ética': [
            'ética', 'ethics', 'ético', 'moral', 'bioética', 'bioethics',
            'responsabilidade', 'transparency', 'transparência'
        ],
        'Saúde': [
            'saúde', 'health', 'medicina', 'medical', 'diagnóstico', 
            'clínica', 'hospital', 'paciente', 'patient'
        ],
        'Economia/Trabalho': [
            'economia', 'economy', 'trabalho', 'labor', 'emprego', 
            'indústria', 'industry', 'organizações', 'organizations',
            'empresa', 'mercado', 'market'
        ],
        'Política/Democracia': [
            'democracia', 'democracy', 'política', 'policy', 'político',
            'governo', 'government', 'estado', 'state', 'eleição'
        ],
        'Direito': [
            'direito', 'law', 'legal', 'jurídico', 'justice', 'judicial',
            'tribunal', 'legislação', 'regulation'
        ],
        'IA Generativa (ChatGPT)': [
            'chatgpt', 'gpt', 'generative', 'generativa', 'llm'
        ],
        'Filosofia': [
            'filosofia', 'philosophy', 'epistemolog', 'ontolog',
            'cognição', 'cognition', 'consciência', 'consciousness'
        ],
        'História': [
            'história', 'history', 'histórico', 'historical'
        ],
        'Comunicação': [
            'comunicação', 'communication', 'mídia', 'media'
        ]
    }
    
    title_lower = artigo['title'].lower()
    keywords_str = ' '.join(artigo['keywords']).lower()
    abstract_lower = artigo['abstract'].lower()
    
    # Priorizar título, depois keywords, depois abstract
    for categoria, palavras in categorias.items():
        if any(palavra in title_lower for palavra in palavras):
            return categoria
        elif any(palavra in keywords_str for palavra in palavras):
            return categoria
    
    for categoria, palavras in categorias.items():
        if any(palavra in abstract_lower for palavra in palavras):
            return categoria
    
    return 'Outros'

def processar_artigos(records):
    """Processa todos os registros RIS"""
    print("\n" + "="*80)
    print("PROCESSAMENTO DOS ARTIGOS")
    print("="*80)
    
    artigos = []
    for i, record in enumerate(records, 1):
        artigo = extrair_dados_artigo(record)
        if artigo:
            artigo = verificar_foco_ia(artigo)
            artigos.append(artigo)
        
        if i % 50 == 0 or i == len(records):
            print(f"  Processados: {i}/{len(records)}", end='\r')
    
    print(f"\n✓ {len(artigos)} artigos processados com sucesso")
    return artigos

def gerar_estatisticas(artigos):
    """Gera estatísticas sobre os artigos"""
    print("\n" + "="*80)
    print("ESTATÍSTICAS GERAIS")
    print("="*80)
    
    total = len(artigos)
    mentions_ai = sum(1 for a in artigos if a['mentions_ai'])
    about_ai = sum(1 for a in artigos if a['about_ai'])
    tangenciam = mentions_ai - about_ai
    sem_ia = total - mentions_ai
    
    print(f"Total de artigos: {total}")
    print(f"Mencionam IA: {mentions_ai} ({mentions_ai/total*100:.1f}%)")
    print(f"  → Foco em IA: {about_ai} ({about_ai/total*100:.1f}%)")
    print(f"  → Tangencial: {tangenciam} ({tangenciam/total*100:.1f}%)")
    print(f"Sem relação com IA: {sem_ia} ({sem_ia/total*100:.1f}%)")
    
    return {
        'total': total,
        'mentions_ai': mentions_ai,
        'about_ai': about_ai,
        'tangenciam': tangenciam,
        'sem_ia': sem_ia
    }

def categorizar_artigos_ia(artigos):
    """Categoriza artigos que focam em IA"""
    print("\n" + "="*80)
    print("CATEGORIZAÇÃO TEMÁTICA")
    print("="*80)
    
    ia_focused = [a for a in artigos if a['about_ai']]
    
    categorias = defaultdict(list)
    for artigo in ia_focused:
        categoria = categorizar_artigo(artigo)
        categorias[categoria].append(artigo)
    
    print("\nDistribuição por categoria (artigos com foco em IA):")
    for categoria, arts in sorted(categorias.items(), key=lambda x: len(x[1]), reverse=True):
        porcentagem = len(arts) / len(ia_focused) * 100 if len(ia_focused) > 0 else 0
        print(f"  {categoria}: {len(arts)} ({porcentagem:.1f}%)")
    
    return categorias

# ============================================================================
# FUNÇÕES DE VISUALIZAÇÃO
# ============================================================================

def criar_grafico_foco_ia(stats, output_path):
    """Gráfico: Classificação por foco em IA"""
    print("\n→ Gerando gráfico: Foco em IA")
    
    fig, ax = plt.subplots(figsize=(12, 8))
    
    categorias = ['Foco Principal\nem IA', 'Mencionam IA\n(Tangencial)']
    valores = [stats['about_ai'], stats['tangenciam']]
    cores = ['#A8D5BA', '#C8E6C9']
    
    bars = ax.bar(categorias, valores, color=cores, 
                   edgecolor='black', linewidth=2.5, alpha=0.9)
    
    for bar, valor in zip(bars, valores):
        height = bar.get_height()
        pct = valor/stats['mentions_ai']*100
        
        ax.text(bar.get_x() + bar.get_width()/2., height/2,
                f'{valor}\nartigos',
                ha='center', va='center', 
                fontweight='bold', fontsize=14, color='black')
        
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{pct:.1f}%',
                ha='center', va='bottom', 
                fontweight='bold', fontsize=13, color='black')
    
    ax.set_ylabel('Número de Artigos', fontsize=14, fontweight='bold')
    ax.set_title('Classificação por foco em Inteligência Artificial', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.grid(axis='y', alpha=0.3, linestyle='--')
    ax.set_axisbelow(True)
    ax.set_ylim(0, max(valores) * 1.15)
    
    # Box com resumo
    textstr = f'''RESUMO:
━━━━━━━━━━━━━━━━━━━━━━
Total Analisado: {stats["total"]}
Mencionam IA: {stats["mentions_ai"]} ({stats["mentions_ai"]/stats["total"]*100:.1f}%)
  • Foco em IA: {stats["about_ai"]} ({stats["about_ai"]/stats["total"]*100:.1f}%)
  • Tangencial: {stats["tangenciam"]} ({stats["tangenciam"]/stats["total"]*100:.1f}%)
Sem menção: {stats["sem_ia"]} ({stats["sem_ia"]/stats["total"]*100:.1f}%)'''
    
    props = dict(boxstyle='round', facecolor='wheat', alpha=0.8, edgecolor='black', linewidth=2)
    ax.text(0.98, 0.97, textstr, transform=ax.transAxes, fontsize=11,
            verticalalignment='top', horizontalalignment='right',
            bbox=props, fontfamily='monospace', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  ✓ Salvo: {output_path}")
    plt.show()

def criar_grafico_publicacoes_ano(artigos, output_path):
    """Gráfico: Publicações por ano"""
    print("\n→ Gerando gráfico: Distribuição por ano")
    
    years = [int(a['year']) for a in artigos if a['year'] != 'N/A' and a['year'].isdigit()]
    year_counts = Counter(years)
    
    fig, ax = plt.subplots(figsize=(16, 8))
    
    years_sorted = sorted(year_counts.keys())
    counts = [year_counts[y] for y in years_sorted]
    
    bars = ax.bar(years_sorted, counts, color='#5B9BD5', 
                   edgecolor='black', linewidth=1.5, alpha=0.8)
    
    # Destacar ano com mais publicações
    max_count = max(counts)
    max_idx = counts.index(max_count)
    bars[max_idx].set_color('#FFEB3B')
    bars[max_idx].set_linewidth(2.5)
    
    for bar, count in zip(bars, counts):
        ax.text(bar.get_x() + bar.get_width()/2., bar.get_height(),
                f'{int(count)}', ha='center', va='bottom', 
                fontweight='bold', fontsize=9)
    
    ax.set_xlabel('Ano', fontsize=13, fontweight='bold')
    ax.set_ylabel('Número de Artigos', fontsize=13, fontweight='bold')
    ax.set_title('Distribuição de publicações por ano (1985-2025)', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.grid(axis='y', alpha=0.3, linestyle='--')
    ax.set_axisbelow(True)
    ax.set_ylim(0, max(counts) * 1.15)
    
    if len(years_sorted) > 15:
        plt.xticks(rotation=45, ha='right')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  ✓ Salvo: {output_path}")
    plt.show()

def criar_grafico_top_journals(artigos, output_path, top_n=10):
    """Gráfico: Top N periódicos"""
    print(f"\n→ Gerando gráfico: Top {top_n} periódicos")
    
    journals = [a['journal'] for a in artigos if a['journal'] != 'N/A']
    journal_counts = Counter(journals)
    total = len(journals)
    
    top = journal_counts.most_common(top_n)
    
    fig, ax = plt.subplots(figsize=(14, 10))
    
    names = [j[0][:60] + '...' if len(j[0]) > 60 else j[0] for j in top]
    values = [j[1] for j in top]
    
    colors = plt.cm.Blues(np.linspace(0.4, 0.9, len(names)))
    bars = ax.barh(range(len(names)), values, color=colors, 
                    edgecolor='black', linewidth=1.5, alpha=0.85)
    
    bars[0].set_color('#FFEB3B')
    bars[0].set_linewidth(2.5)
    
    for i, (bar, valor) in enumerate(zip(bars, values)):
        pct = valor/total*100
        ax.text(valor + 0.3, i, f'{valor} ({pct:.1f}%)', 
                va='center', fontweight='bold', fontsize=11)
    
    ax.set_yticks(range(len(names)))
    ax.set_yticklabels(names)
    ax.invert_yaxis()
    ax.set_xlabel('Número de Artigos', fontsize=13, fontweight='bold')
    ax.set_title('Periódicos mais frequentes', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.grid(axis='x', alpha=0.3, linestyle='--')
    ax.set_xlim(0, max(values) * 1.15)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  ✓ Salvo: {output_path}")
    plt.show()

def criar_grafico_outros_journals(artigos, output_path, top_n=10, min_count=2):
    """Gráfico: Periódicos fora do top N"""
    print(f"\n→ Gerando gráfico: Periódicos fora do top {top_n}")
    
    journals = [a['journal'] for a in artigos if a['journal'] != 'N/A']
    journal_counts = Counter(journals)
    total = len(journals)
    
    all_journals = sorted(journal_counts.items(), key=lambda x: x[1], reverse=True)
    outros = [(j, c) for j, c in all_journals[top_n:] if c >= min_count]
    
    if not outros:
        print(f"  ⚠ Não há periódicos fora do top {top_n} com {min_count}+ artigos")
        return
    
    fig, ax = plt.subplots(figsize=(14, max(10, len(outros) * 0.4)))
    
    names = [j[0][:60] + '...' if len(j[0]) > 60 else j[0] for j in outros]
    values = [j[1] for j in outros]
    
    colors = plt.cm.Greens(np.linspace(0.4, 0.9, len(names)))
    bars = ax.barh(range(len(names)), values, color=colors,
                    edgecolor='black', linewidth=1.5, alpha=0.85)
    
    for i, (bar, valor) in enumerate(zip(bars, values)):
        pct = valor/total*100
        ax.text(valor + 0.2, i, f'{valor} ({pct:.1f}%)', 
                va='center', fontweight='bold', fontsize=10)
    
    ax.set_yticks(range(len(names)))
    ax.set_yticklabels(names, fontsize=10)
    ax.invert_yaxis()
    ax.set_xlabel('Número de Artigos', fontsize=13, fontweight='bold')
    ax.set_title('Periódicos menos frequentes', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.grid(axis='x', alpha=0.3, linestyle='--')
    ax.set_xlim(0, max(values) * 1.2)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  ✓ Salvo: {output_path}")
    plt.show()

def criar_grafico_idiomas(artigos, output_path):
    """Gráfico: Distribuição por idioma"""
    print("\n→ Gerando gráfico: Distribuição por idioma")
    
    languages = [a['language'] for a in artigos if a['language'] != 'N/A']
    lang_counts = Counter(languages)
    total = len(languages)
    
    fig, ax = plt.subplots(figsize=(10, 8))
    
    labels = list(lang_counts.keys())
    sizes = list(lang_counts.values())
    colors = plt.cm.Set3(np.linspace(0, 1, len(labels)))
    
    wedges, texts, autotexts = ax.pie(sizes, labels=labels, autopct='%1.1f%%',
                                         colors=colors, startangle=90,
                                         textprops={'fontsize': 12, 'fontweight': 'bold'})
    
    for autotext in autotexts:
        autotext.set_color('white')
        autotext.set_fontsize(13)
    
    for text, size in zip(texts, sizes):
        text.set_text(f'{text.get_text()}\n({size})')
    
    ax.set_title('Distribuição por idioma', fontsize=14, fontweight='bold', pad=20)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  ✓ Salvo: {output_path}")
    plt.show()

def criar_grafico_citavel(dados_csv, output_path):
    """Gráfico: Documentos citáveis vs não citáveis"""
    print("\n→ Gerando gráfico: Citável vs não citável")
    
    citavel = dados_csv['citavel']
    
    fig, ax = plt.subplots(figsize=(10, 8))
    
    labels = list(citavel.keys())
    sizes = list(citavel.values())
    colors = ['#66C2A5', '#FC8D62']
    explode = (0.05, 0.05)
    
    wedges, texts, autotexts = ax.pie(sizes, labels=labels, autopct='%1.1f%%',
                                         colors=colors, startangle=90, explode=explode,
                                         textprops={'fontsize': 13, 'fontweight': 'bold'})
    
    for autotext in autotexts:
        autotext.set_color('white')
        autotext.set_fontsize(14)
    
    for text, size in zip(texts, sizes):
        text.set_text(f'{text.get_text()}\n({size} docs)')
    
    ax.set_title('Documentos citáveis', fontsize=14, fontweight='bold', pad=20)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  ✓ Salvo: {output_path}")
    plt.show()

def criar_grafico_indice_citacoes(dados_csv, output_path):
    """Gráfico: Índice de citações WoS"""
    print("\n→ Gerando gráfico: Índice de citações")
    
    citacoes = dados_csv['citacoes']
    total = sum(citacoes.values())
    
    fig, ax = plt.subplots(figsize=(12, 8))
    
    indices = list(citacoes.keys())
    values = list(citacoes.values())
    colors = ['#8DD3C7', '#FFFFB3', '#BEBADA'][:len(indices)]
    
    bars = ax.barh(range(len(indices)), values, color=colors, 
                    edgecolor='black', linewidth=2, alpha=0.85)
    
    for i, (bar, valor) in enumerate(zip(bars, values)):
        pct = valor/total*100
        ax.text(valor + 0.5, i, f'{valor} ({pct:.1f}%)', 
                va='center', fontweight='bold', fontsize=12)
    
    ax.set_yticks(range(len(indices)))
    ax.set_yticklabels(indices)
    ax.invert_yaxis()
    ax.set_xlabel('Número de Publicações', fontsize=13, fontweight='bold')
    ax.set_title('Índice de citações WoS', fontsize=14, fontweight='bold', pad=20)
    ax.grid(axis='x', alpha=0.3, linestyle='--')
    ax.set_xlim(0, max(values) * 1.2)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  ✓ Salvo: {output_path}")
    plt.show()

def criar_grafico_areas_tematicas(dados_csv, output_path, top_n=10):
    """Gráfico: Top N áreas temáticas WoS"""
    print(f"\n→ Gerando gráfico: Top {top_n} áreas temáticas")
    
    areas = dados_csv['areas_tematicas']
    total = sum(areas.values())
    
    top = sorted(areas.items(), key=lambda x: x[1], reverse=True)[:top_n]
    
    fig, ax = plt.subplots(figsize=(14, 10))
    
    names = [a[0] for a in top]
    values = [a[1] for a in top]
    colors = plt.cm.Purples(np.linspace(0.4, 0.9, len(names)))
    
    bars = ax.barh(range(len(names)), values, color=colors, 
                    edgecolor='black', linewidth=1.5, alpha=0.85)
    
    bars[0].set_color('#FFEB3B')
    bars[0].set_linewidth(2.5)
    
    for i, (bar, valor) in enumerate(zip(bars, values)):
        pct = valor/total*100
        ax.text(valor + 0.5, i, f'{valor} ({pct:.1f}%)', 
                va='center', fontweight='bold', fontsize=11)
    
    ax.set_yticks(range(len(names)))
    ax.set_yticklabels(names)
    ax.invert_yaxis()
    ax.set_xlabel('Número de Menções', fontsize=13, fontweight='bold')
    ax.set_title('Áreas temáticas WoS mais frequentes', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.grid(axis='x', alpha=0.3, linestyle='--')
    ax.set_xlim(0, max(values) * 1.15)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  ✓ Salvo: {output_path}")
    plt.show()

def criar_grafico_outras_areas(dados_csv, output_path, top_n=10, min_count=3):
    """Gráfico: Áreas temáticas fora do top N"""
    print(f"\n→ Gerando gráfico: Áreas fora do top {top_n}")
    
    areas = dados_csv['areas_tematicas']
    total = sum(areas.values())
    
    all_areas = sorted(areas.items(), key=lambda x: x[1], reverse=True)
    outras = [(a, c) for a, c in all_areas[top_n:] if c >= min_count]
    
    if not outras:
        print(f"  ⚠ Não há áreas fora do top {top_n} com {min_count}+ menções")
        return
    
    fig, ax = plt.subplots(figsize=(14, max(10, len(outras) * 0.4)))
    
    names = [a[0] for a in outras]
    values = [a[1] for a in outras]
    colors = plt.cm.Purples(np.linspace(0.4, 0.9, len(names)))
    
    bars = ax.barh(range(len(names)), values, color=colors,
                    edgecolor='black', linewidth=1.5, alpha=0.85)
    
    for i, (bar, valor) in enumerate(zip(bars, values)):
        pct = valor/total*100
        ax.text(valor + 0.3, i, f'{valor} ({pct:.1f}%)', 
                va='center', fontweight='bold', fontsize=10)
    
    ax.set_yticks(range(len(names)))
    ax.set_yticklabels(names, fontsize=10)
    ax.invert_yaxis()
    ax.set_xlabel('Número de Menções', fontsize=13, fontweight='bold')
    ax.set_title('Áreas temáticas menos frequentes', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.grid(axis='x', alpha=0.3, linestyle='--')
    ax.set_xlim(0, max(values) * 1.2)
    
    # Adicionar informação sobre áreas com 1-2 menções
    areas_poucas = [(a, c) for a, c in all_areas[top_n:] if c < min_count]
    if areas_poucas:
        n_poucas = len(areas_poucas)
        total_poucas = sum(c for _, c in areas_poucas)
        textstr = f'{n_poucas} áreas com 1-2 menções ({total_poucas} menções totais)'
        ax.text(0.02, 0.02, textstr, transform=ax.transAxes,
                fontsize=10, verticalalignment='bottom',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  ✓ Salvo: {output_path}")
    plt.show()

def criar_grafico_categorias_tematicas(categorias, total_ia, output_path):
    """Gráfico: Categorias temáticas dos artigos com foco em IA"""
    print("\n→ Gerando gráfico: Categorias temáticas (foco IA)")
    
    if total_ia == 0:
        print("  ⚠ Nenhum artigo com foco em IA para categorizar")
        return
    
    sorted_cats = sorted(categorias.items(), key=lambda x: len(x[1]), reverse=True)
    
    fig, ax = plt.subplots(figsize=(12, max(8, len(sorted_cats) * 0.5)))
    
    labels = [c[0] for c in sorted_cats]
    values = [len(c[1]) for c in sorted_cats]
    colors = plt.cm.Set3(np.linspace(0, 1, len(labels)))
    
    bars = ax.barh(range(len(labels)), values, color=colors,
                    edgecolor='black', linewidth=2, alpha=0.9)
    
    for i, (bar, valor) in enumerate(zip(bars, values)):
        pct = valor/total_ia*100
        ax.text(valor + 0.3, i, f'{valor} ({pct:.1f}%)', 
                va='center', fontweight='bold', fontsize=11)
    
    ax.set_yticks(range(len(labels)))
    ax.set_yticklabels(labels)
    ax.set_xlabel('Número de Artigos', fontsize=13, fontweight='bold')
    ax.set_title('Categorias temática com foco em Inteligência Artificial', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.invert_yaxis()
    ax.grid(axis='x', alpha=0.3, linestyle='--')
    ax.set_xlim(0, max(values) * 1.15)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  ✓ Salvo: {output_path}")
    plt.show()

# ============================================================================
# RELATÓRIO DETALHADO
# ============================================================================

def gerar_relatorio_detalhado(categorias, artigos, stats, dados_csv, output_path):
    """Gera relatório textual detalhado"""
    print("\n→ Gerando relatório detalhado")
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("RELATÓRIO: ARTIGOS SCIELO COM FOCO EM INTELIGÊNCIA ARTIFICIAL\n")
        f.write("Análise combinada de dados RIS e CSV\n")
        f.write("="*80 + "\n\n")
        
        # Estatísticas gerais
        f.write("ESTATÍSTICAS GERAIS\n")
        f.write("-"*80 + "\n")
        f.write(f"Total de artigos analisados: {stats['total']}\n")
        f.write(f"Mencionam IA: {stats['mentions_ai']} ({stats['mentions_ai']/stats['total']*100:.1f}%)\n")
        f.write(f"  • Foco em IA: {stats['about_ai']} ({stats['about_ai']/stats['total']*100:.1f}%)\n")
        f.write(f"  • Tangencial: {stats['tangenciam']} ({stats['tangenciam']/stats['total']*100:.1f}%)\n")
        f.write(f"Sem relação com IA: {stats['sem_ia']} ({stats['sem_ia']/stats['total']*100:.1f}%)\n\n")
        
        # Dados dos CSVs
        f.write("DADOS ADICIONAIS\n")
        f.write("-"*80 + "\n\n")
        
        f.write("Tipo de Literatura:\n")
        for tipo, count in sorted(dados_csv['literatura'].items(), key=lambda x: x[1], reverse=True):
            f.write(f"  • {tipo}: {count}\n")
        f.write("\n")
        
        f.write("Documentos Citáveis:\n")
        for cat, count in dados_csv['citavel'].items():
            f.write(f"  • {cat}: {count}\n")
        f.write("\n")
        
        f.write("Índices de Citação WoS:\n")
        for indice, count in sorted(dados_csv['citacoes'].items(), key=lambda x: x[1], reverse=True):
            f.write(f"  • {indice}: {count}\n")
        f.write("\n\n")
        
        # Categorias temáticas
        if stats['about_ai'] > 0:
            f.write("CATEGORIAS TEMÁTICAS (ARTIGOS COM FOCO EM IA)\n")
            f.write("-"*80 + "\n\n")
            
            for categoria, arts in sorted(categorias.items(), key=lambda x: len(x[1]), reverse=True):
                pct = len(arts) / stats['about_ai'] * 100
                f.write(f"### {categoria.upper()} ({len(arts)} artigos - {pct:.1f}%)\n")
                f.write("-"*80 + "\n\n")
                
                for i, art in enumerate(arts, 1):
                    f.write(f"{i}. [{art['year']}] {art['title']}\n")
                    f.write(f"   Periódico: {art['journal']}\n")
                    if art['keywords']:
                        f.write(f"   Palavras-chave: {', '.join(art['keywords'][:8])}\n")
                    f.write("\n")
                
                f.write("\n")
        
        # Top periódicos
        f.write("TOP 10 PERIÓDICOS\n")
        f.write("-"*80 + "\n")
        top_periodicos = sorted(dados_csv['periodicos'].items(), key=lambda x: x[1], reverse=True)[:10]
        for i, (periodico, count) in enumerate(top_periodicos, 1):
            f.write(f"{i}. {periodico}: {count} artigos\n")
        f.write("\n\n")
        
        # Top áreas
        f.write("TOP 10 ÁREAS TEMÁTICAS WoS\n")
        f.write("-"*80 + "\n")
        top_areas = sorted(dados_csv['areas_tematicas'].items(), key=lambda x: x[1], reverse=True)[:10]
        for i, (area, count) in enumerate(top_areas, 1):
            f.write(f"{i}. {area}: {count}\n")
        f.write("\n\n")
        
        f.write("="*80 + "\n")
        f.write("FIM DO RELATÓRIO\n")
        f.write("="*80 + "\n")
    
    print(f"  ✓ Salvo: {output_path}")

# ============================================================================
# FUNÇÃO PRINCIPAL
# ============================================================================

def main():
    """Função principal"""
    print("\n")
    print("╔" + "="*78 + "╗")
    print("║" + "ANÁLISE BIBLIOMÉTRICA: SCIELO - INTELIGÊNCIA ARTIFICIAL".center(80) + "║")
    print("║" + "Versão otimizada e revisada".center(80) + "║")
    print("╚" + "="*78 + "╝")
    print("\n")
    
    print(f"Arquivo RIS: {ARQUIVO_RIS}")
    print(f"Diretório de saída: {OUTPUT_DIR}")
    
    try:
        # Carregar dados CSV
        dados_csv = carregar_dados_csv()
        
        # Processar arquivo RIS
        records = ler_arquivo_ris(ARQUIVO_RIS)
        if not records:
            print("\n✗ Não foi possível continuar sem o arquivo RIS.")
            input("Pressione ENTER para sair...")
            return
        
        artigos = processar_artigos(records)
        stats = gerar_estatisticas(artigos)
        categorias = categorizar_artigos_ia(artigos)
        
        # Gerar visualizações
        print("\n" + "="*80)
        print("GERANDO VISUALIZAÇÕES")
        print("="*80)
        
        criar_grafico_foco_ia(stats, os.path.join(OUTPUT_DIR, '01_foco_ia.png'))
        criar_grafico_publicacoes_ano(artigos, os.path.join(OUTPUT_DIR, '02_publicacoes_ano.png'))
        criar_grafico_top_journals(artigos, os.path.join(OUTPUT_DIR, '03a_top10_journals.png'))
        criar_grafico_outros_journals(artigos, os.path.join(OUTPUT_DIR, '03b_outros_journals.png'))
        criar_grafico_idiomas(artigos, os.path.join(OUTPUT_DIR, '04_idiomas.png'))
        criar_grafico_citavel(dados_csv, os.path.join(OUTPUT_DIR, '06_citavel.png'))
        criar_grafico_indice_citacoes(dados_csv, os.path.join(OUTPUT_DIR, '07_indice_citacoes.png'))
        criar_grafico_areas_tematicas(dados_csv, os.path.join(OUTPUT_DIR, '08a_top10_areas.png'))
        criar_grafico_outras_areas(dados_csv, os.path.join(OUTPUT_DIR, '08b_outras_areas.png'))
        criar_grafico_categorias_tematicas(categorias, stats['about_ai'], 
                                           os.path.join(OUTPUT_DIR, '09_categorias_ia.png'))
        
        # Gerar relatório
        gerar_relatorio_detalhado(categorias, artigos, stats, dados_csv, 
                                  os.path.join(OUTPUT_DIR, 'relatorio_completo.txt'))
        
        print("\n" + "="*80)
        print("✓✓✓ ANÁLISE CONCLUÍDA COM SUCESSO ✓✓✓")
        print("="*80)
        print(f"\nArquivos salvos em: {OUTPUT_DIR}")
        print("\nGRÁFICOS GERADOS (11 arquivos):")
        print("  01_foco_ia.png")
        print("  02_publicacoes_ano.png")
        print("  03a_top10_journals.png")
        print("  03b_outros_journals.png")
        print("  04_idiomas.png")
        print("  06_citavel.png")
        print("  07_indice_citacoes.png")
        print("  08a_top10_areas.png ← CORRIGIDO (Education consolidado)")
        print("  08b_outras_areas.png")
        print("  09_categorias_ia.png")
        print("\n  relatorio_completo.txt")
        print("="*80 + "\n")
        
        # Abrir pasta de resultados
        input("Pressione ENTER para abrir a pasta de resultados...")
        import subprocess
        subprocess.Popen(f'explorer "{OUTPUT_DIR}"')
        
    except Exception as e:
        print(f"\n✗ ERRO: {e}")
        import traceback
        traceback.print_exc()
        input("\nPressione ENTER para sair...")

if __name__ == "__main__":
    main()
